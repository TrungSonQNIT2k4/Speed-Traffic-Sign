import av
import cv2
import time
import queue
import streamlit as st
import streamlit.components.v1 as components
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
from ultralytics import YOLO

# --- 1. H√ÄM X·ª¨ L√ù FONT TI·∫æNG VI·ªÜT (FIX L·ªñI √î VU√îNG) ---
def remove_accents(input_str):
    """
    Chuy·ªÉn ƒë·ªïi ti·∫øng Vi·ªát c√≥ d·∫•u th√†nh kh√¥ng d·∫•u in hoa.
    V√≠ d·ª•: "Gi·ªõi h·∫°n t·ªëc ƒë·ªô" -> "GIOI HAN TOC DO"
    """
    s1 = u'√Ä√Å√Ç√É√à√â√ä√å√ç√í√ì√î√ï√ô√ö√ù√†√°√¢√£√®√©√™√¨√≠√≤√≥√¥√µ√π√∫√ΩƒÇƒÉƒêƒëƒ®ƒ©≈®≈©∆†∆°∆Ø∆∞·∫†·∫°·∫¢·∫£·∫§·∫•·∫¶·∫ß·∫®·∫©·∫™·∫´·∫¨·∫≠·∫Æ·∫Ø·∫∞·∫±·∫≤·∫≥·∫¥·∫µ·∫∂·∫∑·∫∏·∫π·∫∫·∫ª·∫º·∫Ω·∫æ·∫ø·ªÄ·ªÅ·ªÇ·ªÉ·ªÑ·ªÖ·ªÜ·ªá·ªà·ªâ·ªä·ªã·ªå·ªç·ªé·ªè·ªê·ªë·ªí·ªì·ªî·ªï·ªñ·ªó·ªò·ªô·ªö·ªõ·ªú·ªù·ªû·ªü·ª†·ª°·ª¢·ª£·ª§·ª•·ª¶·ªß·ª®·ª©·ª™·ª´·ª¨·ª≠·ªÆ·ªØ·ª∞·ª±·ª≤·ª≥·ª¥·ªµ·ª∂·ª∑·ª∏·ªπ'
    s0 = u'AAAAEEEIIOOOUUYaaaaeeeiiooouuyAaDdIiUuOoUuAaAaAaAaAaAaAaAaAaAaAaAaEeEeEeEeEeEeEeEeIiIiOoOoOoOoOoOoOoOoOoOoOoOoUuUuUuUuUuUuUuYyYyYyYy'
    s = ''
    for c in input_str:
        if c in s1:
            s += s0[s1.index(c)]
        else:
            s += c
    return s.upper()

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="Nh·∫≠n di·ªán Bi·ªÉn b√°o", page_icon="üö¶", layout="centered")

# Ti√™u ƒë·ªÅ HTML thu·∫ßn
components.html("""
    <h2 style='text-align: center; color: #333; font-family: sans-serif;'>üö¶ AI Bi·ªÉn B√°o (Final Release)</h2>
""", height=60)

# 2. H√†ng ƒë·ª£i tin nh·∫Øn
result_queue = queue.Queue()

# 3. Load Model
@st.cache_resource
def load_model():
    return YOLO('best.pt')

try:
    model = load_model()
except Exception as e:
    st.error(f"‚ùå L·ªói model: {e}")
    st.stop()

# 4. T·ª´ ƒëi·ªÉn (C·ª© vi·∫øt ti·∫øng Vi·ªát c√≥ d·∫•u b√¨nh th∆∞·ªùng)
CLASS_MESSAGES = {
    "khu_vuc_dong_dan_cu": "Khu v·ª±c ƒë√¥ng d√¢n c∆∞",
    "het_khu_vuc_dong_dan_cu": "H·∫øt khu v·ª±c ƒë√¥ng d√¢n c∆∞",
    "cam_quay_dau": "C·∫•m quay ƒë·∫ßu",
    "cam_di_nguoc_chieu": "Nguy hi·ªÉm ƒëi ng∆∞·ª£c chi·ªÅu",
    "gioi_han_toc_do_50": "Gi·ªõi h·∫°n t·ªëc ƒë·ªô 50",
    "gioi_han_toc_do_60": "Gi·ªõi h·∫°n t·ªëc ƒë·ªô 60",
    "cam_vuot": "C·∫•m v∆∞·ª£t",
    # Th√™m class kh√°c...
}

# Bi·∫øn ki·ªÉm so√°t gi·ªçng n√≥i
last_spoken_time = {}
COOLDOWN = 5.0 

# 5. H√†m v·∫Ω HUD (ƒê√£ t√≠ch h·ª£p x√≥a d·∫•u)
def draw_hud(image, text):
    # Chuy·ªÉn th√†nh KH√îNG D·∫§U tr∆∞·ªõc khi v·∫Ω
    clean_text = remove_accents(text)
    
    h, w, _ = image.shape
    # V·∫Ω n·ªÅn ƒëen d∆∞·ªõi ƒë√°y
    cv2.rectangle(image, (0, h-60), (w, h), (0, 0, 0), -1)
    # V·∫Ω vi·ªÅn v√†ng cho n·ªïi
    cv2.rectangle(image, (0, h-60), (w, h), (0, 255, 255), 2)
    
    # C·∫•u h√¨nh font
    font_scale = 0.9 if w < 500 else 1.3
    thickness = 2
    
    # T√≠nh v·ªã tr√≠ cƒÉn gi·ªØa
    text_size = cv2.getTextSize(clean_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0]
    text_x = (w - text_size[0]) // 2
    
    # V·∫Ω ch·ªØ
    cv2.putText(image, clean_text, (text_x, h-20), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 255), thickness)

# 6. H√†m x·ª≠ l√Ω AI
def video_frame_callback(frame):
    global last_spoken_time
    img = frame.to_ndarray(format="bgr24")
    
    results = model.predict(img, conf=0.5, verbose=False)
    
    message_to_speak = None
    display_text = ""
    current_time = time.time()

    for r in results:
        img = r.plot() # V·∫Ω khung YOLO
        
        for box in r.boxes:
            cls_id = int(box.cls[0])
            name = model.names[cls_id]
            
            if name in CLASS_MESSAGES:
                raw_text = CLASS_MESSAGES[name]
                display_text = raw_text # L∆∞u text g·ªëc ƒë·ªÉ hi·ªÉn th·ªã
                
                # Logic Cooldown
                if (name not in last_spoken_time) or (current_time - last_spoken_time[name] > COOLDOWN):
                    last_spoken_time[name] = current_time
                    message_to_speak = raw_text # L∆∞u text ƒë·ªÉ ƒë·ªçc
                
                break

    # 1. V·∫Ω HUD (D√πng h√†m ƒë√£ fix font)
    if display_text:
        draw_hud(img, display_text) 

    # 2. G·ª≠i l·ªánh n√≥i v√†o h√†ng ƒë·ª£i
    if message_to_speak:
        try:
            result_queue.put_nowait(message_to_speak)
        except queue.Full:
            pass

    return av.VideoFrame.from_ndarray(img, format="bgr24")

# --- GIAO DI·ªÜN CH√çNH ---

RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [
        {"urls": ["stun:stun.l.google.com:19302"]},
        {"urls": ["stun:global.stun.twilio.com:3478"]}
    ]}
)

st.warning("üëá D√†nh cho iPhone: B·∫•m n√∫t d∆∞·ªõi ƒë·ªÉ k√≠ch ho·∫°t loa")
if st.button("üîä K√çCH HO·∫†T LOA IPHONE"):
    components.html("""
    <script>
        window.speechSynthesis.cancel();
        var msg = new SpeechSynthesisUtterance("ƒê√£ k·∫øt n·ªëi loa");
        msg.lang = 'vi-VN';
        window.speechSynthesis.speak(msg);
    </script>
    """, height=0)

# Ch·ªçn thi·∫øt b·ªã
camera_type = st.radio("Ch·ªçn:", ("Laptop", "ƒêi·ªán tho·∫°i (Cam sau)"), horizontal=True)

if "ƒêi·ªán tho·∫°i" in camera_type:
    # C·∫§U H√åNH M·∫†NH CHO IPHONE:
    # 1. facingMode: exact environment -> √âp bu·ªôc cam sau
    # 2. width/height: ideal -> Y√™u c·∫ßu ƒë·ªô ph√¢n gi·∫£i cao (cam sau th∆∞·ªùng n√©t h∆°n)
    video_constraints = {
        "facingMode": {"exact": "environment"},
        "width": {"ideal": 1280},
        "height": {"ideal": 720}
    }
else:
    video_constraints = {"facingMode": "user"}

# WebRTC Streamer
ctx = webrtc_streamer(
    key="final-hud-v5", # ƒê·ªïi key ƒë·ªÉ reset s·∫°ch s·∫Ω
    mode=WebRtcMode.SENDRECV,
    rtc_configuration=RTC_CONFIGURATION,
    media_stream_constraints={"video": video_constraints, "audio": False},
    video_frame_callback=video_frame_callback,
    async_processing=True,
)

# --- X·ª¨ L√ù GI·ªåNG N√ìI (T·ªêI ∆ØU CHO IPHONE) ---
js_placeholder = st.empty()

if ctx.state.playing:
    while True:
        if not ctx.state.playing:
            break

        try:
            # TƒÉng timeout l√™n 1s ƒë·ªÉ gi·∫£m t·∫£i v√≤ng l·∫∑p
            text = result_queue.get(timeout=1.0)
            
            with js_placeholder:
                components.html(f"""
                <script>
                    if ('speechSynthesis' in window) {{
                        window.speechSynthesis.cancel(); 
                        var msg = new SpeechSynthesisUtterance("{text}");
                        msg.lang = 'vi-VN'; 
                        msg.rate = 1.1;
                        window.speechSynthesis.speak(msg);
                    }}
                </script>
                """, height=0, width=0)
            
            # QUAN TR·ªåNG: Ng·ªß 3 gi√¢y sau khi n√≥i ƒë·ªÉ iPhone kh√¥ng b·ªã "s·ªëc nhi·ªát"
            time.sleep(3.0) 
            
        except queue.Empty:
            time.sleep(0.1)