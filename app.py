import av
import queue
import time
import streamlit as st
import streamlit.components.v1 as components # <--- QUAN TR·ªåNG: Th∆∞ vi·ªán n√†y gi√∫p n√© l·ªói
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
from ultralytics import YOLO

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Nh·∫≠n di·ªán Bi·ªÉn b√°o", page_icon="üö¶", layout="centered")
st.title("üö¶ AI Bi·ªÉn b√°o - Fix iOS")

# 1. H√†ng ƒë·ª£i g·ª≠i tin nh·∫Øn
result_queue = queue.Queue()

# 2. Load Model
@st.cache_resource
def load_model():
    return YOLO('best.pt')

try:
    model = load_model()
except Exception as e:
    st.error(f"L·ªói model: {e}")
    st.stop()

# 3. T·ª´ ƒëi·ªÉn l·ªùi tho·∫°i
CLASS_MESSAGES = {
    "khu_vuc_dong_dan_cu": "Khu v·ª±c ƒë√¥ng d√¢n c∆∞",
    "het_khu_vuc_dong_dan_cu": "H·∫øt khu v·ª±c ƒë√¥ng d√¢n c∆∞",
    "cam_quay_dau": "C·∫•m quay ƒë·∫ßu",
    "cam_di_nguoc_chieu": "ƒêi ng∆∞·ª£c chi·ªÅu",
    "gioi_han_toc_do_50": "T·ªëc ƒë·ªô 50",
    "gioi_han_toc_do_60": "T·ªëc ƒë·ªô 60",
    "cam_vuot": "C·∫•m v∆∞·ª£t",
    # Th√™m c√°c l·ªõp kh√°c...
}

# 4. X·ª≠ l√Ω AI
def video_frame_callback(frame):
    img = frame.to_ndarray(format="bgr24")
    results = model.predict(img, conf=0.5, verbose=False)
    
    found_labels = []
    for r in results:
        for box in r.boxes:
            cls_id = int(box.cls[0])
            name = model.names[cls_id]
            if name in CLASS_MESSAGES:
                found_labels.append(CLASS_MESSAGES[name])
    
    if found_labels:
        try:
            result_queue.put_nowait(found_labels[0])
        except queue.Full:
            pass

    annotated_frame = results[0].plot()
    return av.VideoFrame.from_ndarray(annotated_frame, format="bgr24")

# --- GIAO DI·ªÜN CH√çNH ---

RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [
        {"urls": ["stun:stun.l.google.com:19302"]},
        {"urls": ["stun:global.stun.twilio.com:3478"]}
    ]}
)

camera_type = st.radio("Ch·ªçn thi·∫øt b·ªã:", ("Laptop", "ƒêi·ªán tho·∫°i (Cam sau)"), horizontal=True)
if "ƒêi·ªán tho·∫°i" in camera_type:
    video_constraints = {"facingMode": "environment"}
else:
    video_constraints = {"facingMode": "user"}

ctx = webrtc_streamer(
    key="mobile-fix-v2",
    mode=WebRtcMode.SENDRECV,
    rtc_configuration=RTC_CONFIGURATION,
    media_stream_constraints={"video": video_constraints, "audio": False},
    video_frame_callback=video_frame_callback,
    async_processing=True,
)

# --- PH·∫¶N JS (ƒê√É S·ª¨A ƒê·ªÇ KH√îNG B·ªä L·ªñI TR√äN IPHONE C≈®) ---

status_placeholder = st.empty()
js_placeholder = st.empty()

# N√∫t k√≠ch ho·∫°t (D√πng components.html ƒë·ªÉ tr√°nh l·ªói Regex)
if st.button("üîä K√çCH HO·∫†T LOA (B·∫•m 1 l·∫ßn)"):
    components.html("""
    <script>
        window.speechSynthesis.cancel(); // D·ª´ng c√°c √¢m thanh c≈©
        var msg = new SpeechSynthesisUtterance("ƒê√£ k√≠ch ho·∫°t");
        msg.lang = 'vi-VN';
        window.speechSynthesis.speak(msg);
    </script>
    """, height=0, width=0)

if ctx.state.playing:
    while True:
        try:
            text_to_speak = result_queue.get(timeout=0.1)
            status_placeholder.warning(f"‚ö†Ô∏è Ph√°t hi·ªán: {text_to_speak}")
            
            # --- ƒê√ÇY L√Ä CH·ªñ S·ª¨A QUAN TR·ªåNG ---
            # D√πng components.html thay v√¨ st.write
            # N√≥ gi√∫p bypass b·ªô l·ªçc MathJax g√¢y l·ªói tr√™n iOS c≈©
            with js_placeholder:
                components.html(f"""
                    <script>
                        window.speechSynthesis.cancel(); 
                        var msg = new SpeechSynthesisUtterance("{text_to_speak}");
                        msg.lang = 'vi-VN';
                        msg.rate = 1.1;
                        window.speechSynthesis.speak(msg);
                    </script>
                """, height=0, width=0)
            
            time.sleep(2.5) # ƒê·ª£i n√≥i xong m·ªõi nh·∫≠n ti·∫øp
            js_placeholder.empty()
            
        except queue.Empty:
            time.sleep(0.1)